{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "g9oBlV_0pRJJ",
        "y6Mh-olyp9pc"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "H7MVJCccrmjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Currently the model's accuracy is hovering between 50-60%, it's crucial to note that it successfully validates the underlying concept. This initial success provides a solid base for subsequent development and fine-tuning."
      ],
      "metadata": {
        "id": "wtixv06fE70s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "YGyQcklEERwt",
        "outputId": "cf23526f-936d-4a20-cbb6-d50ef18d2bec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        type           artist                        song_title  popularity  \\\n",
              "544   hiphop      Bliss n Eso  Tear The Roof Off (feat. Watsky)          59   \n",
              "404   hiphop    Young Scooter   No Features (feat. Kodak Black)          59   \n",
              "545   hiphop        Lil Tracy                         This Year          57   \n",
              "854    indie     Kina Grannis        Can’t Help Falling in Love          77   \n",
              "1024   indie  Vampire Weekend                          Big Blue          62   \n",
              "\n",
              "      acousticness  danceability  duration_ms  energy  instrumentalness  \\\n",
              "544         0.1610         0.736       206244  0.8900          0.000000   \n",
              "404         0.0435         0.826       208287  0.7580          0.000000   \n",
              "545         0.0718         0.723       120000  0.5300          0.000000   \n",
              "854         0.9050         0.266       201933  0.0596          0.000071   \n",
              "1024        0.8180         0.691       108573  0.3060          0.007980   \n",
              "\n",
              "      liveness  loudness  mode  speechiness    tempo  valence  \n",
              "544     0.1660    -5.070     0       0.2490  142.101    0.679  \n",
              "404     0.1680    -5.616     1       0.0743  119.998    0.410  \n",
              "545     0.1260    -9.754     0       0.2920  160.008    0.237  \n",
              "854     0.1320   -18.515     1       0.0363  181.740    0.143  \n",
              "1024    0.0992    -9.650     1       0.0631  149.965    0.413  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d24b1bbd-689a-4e8d-a526-0758f99b1287\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>artist</th>\n",
              "      <th>song_title</th>\n",
              "      <th>popularity</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>duration_ms</th>\n",
              "      <th>energy</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>liveness</th>\n",
              "      <th>loudness</th>\n",
              "      <th>mode</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "      <th>valence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>544</th>\n",
              "      <td>hiphop</td>\n",
              "      <td>Bliss n Eso</td>\n",
              "      <td>Tear The Roof Off (feat. Watsky)</td>\n",
              "      <td>59</td>\n",
              "      <td>0.1610</td>\n",
              "      <td>0.736</td>\n",
              "      <td>206244</td>\n",
              "      <td>0.8900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.1660</td>\n",
              "      <td>-5.070</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2490</td>\n",
              "      <td>142.101</td>\n",
              "      <td>0.679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>hiphop</td>\n",
              "      <td>Young Scooter</td>\n",
              "      <td>No Features (feat. Kodak Black)</td>\n",
              "      <td>59</td>\n",
              "      <td>0.0435</td>\n",
              "      <td>0.826</td>\n",
              "      <td>208287</td>\n",
              "      <td>0.7580</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.1680</td>\n",
              "      <td>-5.616</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0743</td>\n",
              "      <td>119.998</td>\n",
              "      <td>0.410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545</th>\n",
              "      <td>hiphop</td>\n",
              "      <td>Lil Tracy</td>\n",
              "      <td>This Year</td>\n",
              "      <td>57</td>\n",
              "      <td>0.0718</td>\n",
              "      <td>0.723</td>\n",
              "      <td>120000</td>\n",
              "      <td>0.5300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.1260</td>\n",
              "      <td>-9.754</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2920</td>\n",
              "      <td>160.008</td>\n",
              "      <td>0.237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>854</th>\n",
              "      <td>indie</td>\n",
              "      <td>Kina Grannis</td>\n",
              "      <td>Can’t Help Falling in Love</td>\n",
              "      <td>77</td>\n",
              "      <td>0.9050</td>\n",
              "      <td>0.266</td>\n",
              "      <td>201933</td>\n",
              "      <td>0.0596</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>0.1320</td>\n",
              "      <td>-18.515</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0363</td>\n",
              "      <td>181.740</td>\n",
              "      <td>0.143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1024</th>\n",
              "      <td>indie</td>\n",
              "      <td>Vampire Weekend</td>\n",
              "      <td>Big Blue</td>\n",
              "      <td>62</td>\n",
              "      <td>0.8180</td>\n",
              "      <td>0.691</td>\n",
              "      <td>108573</td>\n",
              "      <td>0.3060</td>\n",
              "      <td>0.007980</td>\n",
              "      <td>0.0992</td>\n",
              "      <td>-9.650</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0631</td>\n",
              "      <td>149.965</td>\n",
              "      <td>0.413</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d24b1bbd-689a-4e8d-a526-0758f99b1287')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d24b1bbd-689a-4e8d-a526-0758f99b1287 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d24b1bbd-689a-4e8d-a526-0758f99b1287');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from numpy import argmax\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "df= pd.read_csv('https://raw.githubusercontent.com/Russoremy/Datasets/main/spotify_classifier.csv')\n",
        "df.sample(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5U4GBF8FcRF",
        "outputId": "da30bb7a-b360-4a1c-a9a8-4d4bcf5dbadb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['type', 'artist', 'song_title', 'popularity', 'acousticness',\n",
            "       'danceability', 'duration_ms', 'energy', 'instrumentalness', 'liveness',\n",
            "       'loudness', 'mode', 'speechiness', 'tempo', 'valence'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['artist', 'song_title', 'popularity', 'acousticness','duration_ms','instrumentalness', 'liveness','loudness', 'mode', 'speechiness','valence'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "wUjcLJS7nshs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split into input and output columns\n",
        "X, y = df.values[:, 1:], df.values[:, 0]"
      ],
      "metadata": {
        "id": "Sq6zW0njnvkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXt1hVTAnxtT",
        "outputId": "706980ab-0435-433a-8292-59d5c403c14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['type', 'danceability', 'energy', 'tempo'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ensure all data are floating point values\n",
        "X = X.astype('float32')"
      ],
      "metadata": {
        "id": "Fnp1nfjZn09Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht4Ki1WXoD77",
        "outputId": "2a7237e5-2aa2-423c-cbbc-85ba1456636d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0.889,   0.596,  97.994],\n",
              "       [  0.793,   0.455, 125.921],\n",
              "       [  0.669,   0.576,  79.042],\n",
              "       ...,\n",
              "       [  0.657,   0.376,  84.905],\n",
              "       [  0.79 ,   0.49 , 140.202],\n",
              "       [  0.653,   0.468,  96.931]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi8E9vwyoHQL",
        "outputId": "b981d79b-9982-4f85-8575-b674e3133987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['hiphop', 'hiphop', 'hiphop', ..., 'indie', 'indie', 'indie'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encode strings to integer\n",
        "y = LabelEncoder().fit_transform(y)"
      ],
      "metadata": {
        "id": "U1RPrDsIoK9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEo51ExxoaMj",
        "outputId": "34f9a3e8-1129-4416-d945-c93c9acc834f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "v7tfynaYEuni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25ba3074-0f63-4346-eb50-8300262f71a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(939, 3) (463, 3) (939,) (463,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Model"
      ],
      "metadata": {
        "id": "wN5RTPAWoz6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# determine the number of input features\n",
        "n_features = X_train.shape[1]\n",
        "n_features\n"
      ],
      "metadata": {
        "id": "TN-aqTYdjFQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af420975-df92-447a-a07c-76494301011f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(Dense(256, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=0)"
      ],
      "metadata": {
        "id": "FVIVVm6ajLI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89eddd4d-405e-4708-ab28-03bfe07bce79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f672ec1cf40>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Tunning"
      ],
      "metadata": {
        "id": "g9oBlV_0pRJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use scikit-learn to grid search the batch size and epochs\n",
        "import numpy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=3, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/Russoremy/Datasets/main/spotify_classifier.csv')\n",
        "\n",
        "# split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "# define the grid search parameters\n",
        "batch_size = [10, 20, 40, 60, 80, 100]\n",
        "epochs = [10, 50, 100]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "4sdquZZLj8gS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a21ae4c7-9549-4302-8f60-e31cc2cd0c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(939, 3) (463, 3) (939,) (463,)\n",
            "Best: 0.619808 using {'batch_size': 10, 'epochs': 50}\n",
            "0.529286 (0.047412) with: {'batch_size': 10, 'epochs': 10}\n",
            "0.619808 (0.050381) with: {'batch_size': 10, 'epochs': 50}\n",
            "0.538871 (0.035989) with: {'batch_size': 10, 'epochs': 100}\n",
            "0.534611 (0.013130) with: {'batch_size': 20, 'epochs': 10}\n",
            "0.548456 (0.024238) with: {'batch_size': 20, 'epochs': 50}\n",
            "0.522897 (0.031340) with: {'batch_size': 20, 'epochs': 100}\n",
            "0.514377 (0.019695) with: {'batch_size': 40, 'epochs': 10}\n",
            "0.534611 (0.023526) with: {'batch_size': 40, 'epochs': 50}\n",
            "0.589989 (0.017756) with: {'batch_size': 40, 'epochs': 100}\n",
            "0.544196 (0.010543) with: {'batch_size': 60, 'epochs': 10}\n",
            "0.501597 (0.021352) with: {'batch_size': 60, 'epochs': 50}\n",
            "0.596379 (0.033945) with: {'batch_size': 60, 'epochs': 100}\n",
            "0.485623 (0.019695) with: {'batch_size': 80, 'epochs': 10}\n",
            "0.495208 (0.054469) with: {'batch_size': 80, 'epochs': 50}\n",
            "0.565495 (0.074563) with: {'batch_size': 80, 'epochs': 100}\n",
            "0.497338 (0.024238) with: {'batch_size': 100, 'epochs': 10}\n",
            "0.501597 (0.070336) with: {'batch_size': 100, 'epochs': 50}\n",
            "0.534611 (0.035417) with: {'batch_size': 100, 'epochs': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use scikit-learn to grid search the batch size and epochs\n",
        "import numpy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(optimizer='adam'):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=3, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/Russoremy/Datasets/main/spotify_classifier.csv')\n",
        "\n",
        "# split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "param_grid = dict(optimizer=optimizer)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdoGbQedAETJ",
        "outputId": "a722f5b7-ad33-43b2-aaf0-ff4777179750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.520965 using {'optimizer': 'Adamax'}\n",
            "0.499527 (0.021715) with: {'optimizer': 'SGD'}\n",
            "0.489730 (0.014917) with: {'optimizer': 'RMSprop'}\n",
            "0.489730 (0.014917) with: {'optimizer': 'Adagrad'}\n",
            "0.495078 (0.017429) with: {'optimizer': 'Adadelta'}\n",
            "0.473671 (0.012602) with: {'optimizer': 'Adam'}\n",
            "0.520965 (0.003519) with: {'optimizer': 'Adamax'}\n",
            "0.504922 (0.017429) with: {'optimizer': 'Nadam'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use scikit-learn to grid search the learning rate and momentum p.s. copy and pasted my edit cause programmer lazy stuff.\n",
        "import numpy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(learn_rate=0.01, momentum=0):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=3, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\toptimizer = SGD(lr=learn_rate, momentum=momentum)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/Russoremy/Datasets/main/spotify_classifier.csv')\n",
        "\n",
        "# split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
        "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
        "param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbai9jftCq0v",
        "outputId": "0a8eb4cb-bc81-4fe9-aa90-961f0c3b6d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.502208 using {'learn_rate': 0.01, 'momentum': 0.9}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.001, 'momentum': 0.0}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.001, 'momentum': 0.2}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.001, 'momentum': 0.4}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.001, 'momentum': 0.6}\n",
            "0.489730 (0.014917) with: {'learn_rate': 0.001, 'momentum': 0.8}\n",
            "0.489730 (0.014917) with: {'learn_rate': 0.001, 'momentum': 0.9}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.01, 'momentum': 0.0}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.01, 'momentum': 0.2}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.01, 'momentum': 0.4}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.01, 'momentum': 0.6}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.01, 'momentum': 0.8}\n",
            "0.502208 (0.017976) with: {'learn_rate': 0.01, 'momentum': 0.9}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.1, 'momentum': 0.0}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.1, 'momentum': 0.2}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.1, 'momentum': 0.4}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.1, 'momentum': 0.6}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.1, 'momentum': 0.8}\n",
            "0.489730 (0.014917) with: {'learn_rate': 0.1, 'momentum': 0.9}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.2, 'momentum': 0.0}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.2, 'momentum': 0.2}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.2, 'momentum': 0.4}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.2, 'momentum': 0.6}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.2, 'momentum': 0.8}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.2, 'momentum': 0.9}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.3, 'momentum': 0.0}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.3, 'momentum': 0.2}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.3, 'momentum': 0.4}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.3, 'momentum': 0.6}\n",
            "0.489730 (0.014917) with: {'learn_rate': 0.3, 'momentum': 0.8}\n",
            "0.482600 (0.005024) with: {'learn_rate': 0.3, 'momentum': 0.9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(init_mode='uniform'):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=3, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/Russoremy/Datasets/main/spotify_classifier.csv')\n",
        "\n",
        "# split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "\n",
        "# define the grid search parameters\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
        "param_grid = dict(init_mode=init_mode)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txUkk6hXQ29d",
        "outputId": "d4fbeca8-557c-4fd5-82bc-87b6c3170dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.674413 using {'init_mode': 'he_uniform'}\n",
            "0.612859 (0.017502) with: {'init_mode': 'uniform'}\n",
            "0.571774 (0.029136) with: {'init_mode': 'lecun_uniform'}\n",
            "0.642268 (0.014605) with: {'init_mode': 'normal'}\n",
            "0.552121 (0.051814) with: {'init_mode': 'zero'}\n",
            "0.649458 (0.032609) with: {'init_mode': 'glorot_normal'}\n",
            "0.648509 (0.020623) with: {'init_mode': 'glorot_uniform'}\n",
            "0.623542 (0.011061) with: {'init_mode': 'he_normal'}\n",
            "0.674413 (0.025017) with: {'init_mode': 'he_uniform'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(activation='relu'):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=3, activation=activation))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/Russoremy/Datasets/main/spotify_classifier.csv')\n",
        "\n",
        "# split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "\n",
        "# define the grid search parameters\n",
        "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
        "param_grid = dict(activation=activation)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aTzT4SpUByb",
        "outputId": "14772789-3423-490d-d756-411b62ed7b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.643212 using {'activation': 'sigmoid'}\n",
            "0.576331 (0.069083) with: {'activation': 'softmax'}\n",
            "0.642261 (0.047277) with: {'activation': 'softplus'}\n",
            "0.641410 (0.016093) with: {'activation': 'softsign'}\n",
            "0.640540 (0.059745) with: {'activation': 'relu'}\n",
            "0.578857 (0.072279) with: {'activation': 'tanh'}\n",
            "0.643212 (0.032419) with: {'activation': 'sigmoid'}\n",
            "0.542475 (0.080932) with: {'activation': 'hard_sigmoid'}\n",
            "0.529945 (0.048329) with: {'activation': 'linear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(dropout_rate=0.0, weight_constraint=0):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=3, kernel_initializer='uniform', activation='linear', kernel_constraint=MaxNorm(weight_constraint)))\n",
        "\tmodel.add(Dropout(dropout_rate))\n",
        "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/Russoremy/Datasets/main/spotify_classifier.csv')\n",
        "\n",
        "# split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "\n",
        "# define the grid search parameters\n",
        "weight_constraint = [1, 2, 3, 4, 5]\n",
        "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvqHZFNgXShX",
        "outputId": "4da07387-9f0a-499a-d532-a5c9da456893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.685128 using {'dropout_rate': 0.0, 'weight_constraint': 1}\n",
            "0.685128 (0.047945) with: {'dropout_rate': 0.0, 'weight_constraint': 1}\n",
            "0.631546 (0.031089) with: {'dropout_rate': 0.0, 'weight_constraint': 2}\n",
            "0.674394 (0.032879) with: {'dropout_rate': 0.0, 'weight_constraint': 3}\n",
            "0.659252 (0.018227) with: {'dropout_rate': 0.0, 'weight_constraint': 4}\n",
            "0.661885 (0.027950) with: {'dropout_rate': 0.0, 'weight_constraint': 5}\n",
            "0.680664 (0.037024) with: {'dropout_rate': 0.1, 'weight_constraint': 1}\n",
            "0.583411 (0.029590) with: {'dropout_rate': 0.1, 'weight_constraint': 2}\n",
            "0.665493 (0.034159) with: {'dropout_rate': 0.1, 'weight_constraint': 3}\n",
            "0.647644 (0.028053) with: {'dropout_rate': 0.1, 'weight_constraint': 4}\n",
            "0.636053 (0.013970) with: {'dropout_rate': 0.1, 'weight_constraint': 5}\n",
            "0.626211 (0.022356) with: {'dropout_rate': 0.2, 'weight_constraint': 1}\n",
            "0.624438 (0.008460) with: {'dropout_rate': 0.2, 'weight_constraint': 2}\n",
            "0.665505 (0.023955) with: {'dropout_rate': 0.2, 'weight_constraint': 3}\n",
            "0.664588 (0.013266) with: {'dropout_rate': 0.2, 'weight_constraint': 4}\n",
            "0.654786 (0.020602) with: {'dropout_rate': 0.2, 'weight_constraint': 5}\n",
            "0.652134 (0.031116) with: {'dropout_rate': 0.3, 'weight_constraint': 1}\n",
            "0.659226 (0.022509) with: {'dropout_rate': 0.3, 'weight_constraint': 2}\n",
            "0.661926 (0.027531) with: {'dropout_rate': 0.3, 'weight_constraint': 3}\n",
            "0.647637 (0.008771) with: {'dropout_rate': 0.3, 'weight_constraint': 4}\n",
            "0.646751 (0.011132) with: {'dropout_rate': 0.3, 'weight_constraint': 5}\n",
            "0.647651 (0.014989) with: {'dropout_rate': 0.4, 'weight_constraint': 1}\n",
            "0.653890 (0.022148) with: {'dropout_rate': 0.4, 'weight_constraint': 2}\n",
            "0.645850 (0.019723) with: {'dropout_rate': 0.4, 'weight_constraint': 3}\n",
            "0.627155 (0.030585) with: {'dropout_rate': 0.4, 'weight_constraint': 4}\n",
            "0.626223 (0.003708) with: {'dropout_rate': 0.4, 'weight_constraint': 5}\n",
            "0.617308 (0.003566) with: {'dropout_rate': 0.5, 'weight_constraint': 1}\n",
            "0.643169 (0.014207) with: {'dropout_rate': 0.5, 'weight_constraint': 2}\n",
            "0.632488 (0.013602) with: {'dropout_rate': 0.5, 'weight_constraint': 3}\n",
            "0.628920 (0.014095) with: {'dropout_rate': 0.5, 'weight_constraint': 4}\n",
            "0.627107 (0.025756) with: {'dropout_rate': 0.5, 'weight_constraint': 5}\n",
            "0.597717 (0.048563) with: {'dropout_rate': 0.6, 'weight_constraint': 1}\n",
            "0.586049 (0.034580) with: {'dropout_rate': 0.6, 'weight_constraint': 2}\n",
            "0.635155 (0.014347) with: {'dropout_rate': 0.6, 'weight_constraint': 3}\n",
            "0.609224 (0.043552) with: {'dropout_rate': 0.6, 'weight_constraint': 4}\n",
            "0.597647 (0.029966) with: {'dropout_rate': 0.6, 'weight_constraint': 5}\n",
            "0.579829 (0.013597) with: {'dropout_rate': 0.7, 'weight_constraint': 1}\n",
            "0.581643 (0.015294) with: {'dropout_rate': 0.7, 'weight_constraint': 2}\n",
            "0.600324 (0.031057) with: {'dropout_rate': 0.7, 'weight_constraint': 3}\n",
            "0.588782 (0.027324) with: {'dropout_rate': 0.7, 'weight_constraint': 4}\n",
            "0.552119 (0.055440) with: {'dropout_rate': 0.7, 'weight_constraint': 5}\n",
            "0.561120 (0.059928) with: {'dropout_rate': 0.8, 'weight_constraint': 1}\n",
            "0.498669 (0.012305) with: {'dropout_rate': 0.8, 'weight_constraint': 2}\n",
            "0.545056 (0.049386) with: {'dropout_rate': 0.8, 'weight_constraint': 3}\n",
            "0.539651 (0.048366) with: {'dropout_rate': 0.8, 'weight_constraint': 4}\n",
            "0.509371 (0.021085) with: {'dropout_rate': 0.8, 'weight_constraint': 5}\n",
            "0.490621 (0.014459) with: {'dropout_rate': 0.9, 'weight_constraint': 1}\n",
            "0.493295 (0.019936) with: {'dropout_rate': 0.9, 'weight_constraint': 2}\n",
            "0.493295 (0.019936) with: {'dropout_rate': 0.9, 'weight_constraint': 3}\n",
            "0.489730 (0.014917) with: {'dropout_rate': 0.9, 'weight_constraint': 4}\n",
            "0.512012 (0.028967) with: {'dropout_rate': 0.9, 'weight_constraint': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(neurons=1):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(neurons, input_dim=3, kernel_initializer='lecun_uniform', activation='linear', kernel_constraint=MaxNorm(5)))\n",
        "\tmodel.add(Dropout(0.0))\n",
        "\tmodel.add(Dense(1, kernel_initializer='lecun_uniform', activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/Russoremy/Datasets/main/spotify_classifier.csv')\n",
        "\n",
        "# split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "\n",
        "# define the grid search parameters\n",
        "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
        "param_grid = dict(neurons=neurons)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZIJjs3na3iD",
        "outputId": "bb511939-8f52-4c28-dca1-be5a3b0b8abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.664602 using {'neurons': 20}\n",
            "0.595929 (0.043548) with: {'neurons': 1}\n",
            "0.621810 (0.035089) with: {'neurons': 5}\n",
            "0.630722 (0.032388) with: {'neurons': 10}\n",
            "0.595929 (0.036914) with: {'neurons': 15}\n",
            "0.664602 (0.017335) with: {'neurons': 20}\n",
            "0.625355 (0.033813) with: {'neurons': 25}\n",
            "0.619057 (0.042898) with: {'neurons': 30}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(15, input_dim=3, kernel_initializer='lecun_uniform', activation='linear', kernel_constraint=MaxNorm(5)))\n",
        "\tmodel.add(Dropout(0.0))\n",
        "\tmodel.add(Dense(1, kernel_initializer='lecun_uniform', activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Nadam(learning_rate=0.3),\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
        ")\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/Russoremy/Datasets/main/spotify_classifier.csv')\n",
        "\n",
        "# split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_scaled,\n",
        "    y_train,\n",
        "    batch_size=10,\n",
        "    epochs=100,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.LearningRateScheduler(\n",
        "            lambda epoch: 1e-3 * 10 ** (epoch / 30)\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "QZGuuFHfk1jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "y6Mh-olyp9pc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# determine the number of input features\n",
        "n_features = X_train.shape[1]\n",
        "n_features\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(Dense(256, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWycu0WIpyok",
        "outputId": "17c9ccc9-d0d2-4a5c-a074-43e5d1d37561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f670a4fa710>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test Accuracy: %.3f' % acc)\n",
        "# make a prediction\n",
        "row = [0.772,\t0.295,\t89.009]\n",
        "yhat = model.predict([row])\n",
        "print('Predicted: %s (class=%d)' % (yhat, argmax(yhat)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISN4YSN4pp3N",
        "outputId": "93977377-e484-4f58-901e-3158a390a0d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.570\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Predicted: [[0.8200614  0.17993857]] (class=0)\n"
          ]
        }
      ]
    }
  ]
}